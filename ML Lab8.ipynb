{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "342c2c24-d9ec-4efa-92e3-31c8d76253ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CountVectorizer\n",
    "d1=\"I love programming\"\n",
    "d2=\"Programming is interesting\"\n",
    "d3=\"I love pizza very very much\"\n",
    "var=[\"I\",\"love\",\"Programming\",\"is\",\"very\",\"interesting\",\"much\",\"pizza\"]\n",
    "d1=[1,1,1,0,0,0,0,0]\n",
    "d2=[0,0,0,1,0,1,0,0]\n",
    "d3=[1,1,0,0,2,0,1,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fc4bfcaa-d42a-401a-9c02-55315ba1a69e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'love': 2, 'programming': 5, 'is': 1, 'interesting': 0, 'pizza': 4, 'very': 6, 'much': 3}\n",
      "[[0 0 1 0 0 1 0]\n",
      " [1 1 0 0 0 1 0]\n",
      " [0 0 1 1 1 0 2]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "d1=\"I love programming\"\n",
    "d2=\"Programming is interesting\"\n",
    "d3=\"I love pizza very very much\"\n",
    "documents=[d1,d2,d3]\n",
    "vectorizer=CountVectorizer()\n",
    "X=vectorizer.fit_transform(documents)\n",
    "print(vectorizer.vocabulary_)\n",
    "print(X.toarray())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "abfe1eb7-ac47-452f-8935-d3e6bcd4a3aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                   text  target       category\n",
      "0     From: degroff@netcom.com (21012d)\\nSubject: Re...       2      sci.space\n",
      "1     From: ab@nova.cc.purdue.edu (Allen B)\\nSubject...       1  comp.graphics\n",
      "2     From: healta@saturn.wwc.edu (Tammy R Healy)\\nS...       0    alt.atheism\n",
      "3     From: capelli@vnet.IBM.COM (Ron Capelli)\\nSubj...       1  comp.graphics\n",
      "4     From: henry@zoo.toronto.edu (Henry Spencer)\\nS...       2      sci.space\n",
      "...                                                 ...     ...            ...\n",
      "1652  From: ab@nova.cc.purdue.edu (Allen B)\\nSubject...       1  comp.graphics\n",
      "1653  From: renes@ecpdsharmony.cern.ch (Rene S. Dutc...       1  comp.graphics\n",
      "1654  From: xrcjd@resolve.gsfc.nasa.gov (Charles J. ...       2      sci.space\n",
      "1655  From: dietz@cs.rochester.edu (Paul Dietz)\\nSub...       2      sci.space\n",
      "1656  From: jhwitten@cs.ruu.nl (Jurriaan Wittenberg)...       2      sci.space\n",
      "\n",
      "[1657 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "df=pd.read_csv(\"Downloads/newsgroups_train.csv\")\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8cab8a20-8433-4e93-902b-a820f3ccafcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                   text  target       category\n",
      "0     From: mccall@mksol.dseg.ti.com (fred j mccall ...       2      sci.space\n",
      "1     From: \"Changyaw Wang\" <wangc@cs.indiana.edu>\\n...       1  comp.graphics\n",
      "2     From: lioness@maple.circa.ufl.edu\\nSubject: Te...       1  comp.graphics\n",
      "3     From: hotopp@ami1.bwi.wec.com (Daniel T. Hotop...       1  comp.graphics\n",
      "4     From: Ad-Robot@bobsbox.rent.com (Robotic Posti...       1  comp.graphics\n",
      "...                                                 ...     ...            ...\n",
      "1097  From: malek@pi.titech.ac.jp (Zidouri Abdelmale...       1  comp.graphics\n",
      "1098  From: livesey@solntze.wpd.sgi.com (Jon Livesey...       0    alt.atheism\n",
      "1099  From: I3150101@dbstu1.rz.tu-bs.de (Benedikt Ro...       0    alt.atheism\n",
      "1100  From: beck@irzr17.inf.tu-dresden.de (Andre Bec...       1  comp.graphics\n",
      "1101  From: 18084TM@msu.edu (Tom)\\nSubject: Billboar...       2      sci.space\n",
      "\n",
      "[1102 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "df=pd.read_csv(\"Downloads/newsgroups_test.csv\")\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fba3cc02-fb95-47f9-bcd8-9b758dc0bd45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                   text  target  \\\n",
      "0     I am a little confused on all of the models of...       7   \n",
      "1     I'm not familiar at all with the format of the...       5   \n",
      "2                                   \\nIn a word, yes.\\n       0   \n",
      "3     \\nThey were attacking the Iraqis to drive them...      17   \n",
      "4     \\nI've just spent two solid months arguing tha...      19   \n",
      "...                                                 ...     ...   \n",
      "7527  \\n   Henry, if I read you correctly, you may b...      14   \n",
      "7528  about\\nthem on\\n\\nActually, I thought Macs wer...       4   \n",
      "7529  I sent a version of this post out a while ago,...       9   \n",
      "7530  I have this kit which includes the following :...       6   \n",
      "7531  \\nFine, but one of the points of this entire d...      15   \n",
      "\n",
      "                    category  \n",
      "0                  rec.autos  \n",
      "1             comp.windows.x  \n",
      "2                alt.atheism  \n",
      "3      talk.politics.mideast  \n",
      "4         talk.religion.misc  \n",
      "...                      ...  \n",
      "7527               sci.space  \n",
      "7528   comp.sys.mac.hardware  \n",
      "7529      rec.sport.baseball  \n",
      "7530            misc.forsale  \n",
      "7531  soc.religion.christian  \n",
      "\n",
      "[7532 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "df=pd.read_csv(\"Downloads/nlp_test.csv\")\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41ed6d69-0ce3-4b6a-89da-4d38240d694b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                    text  target  \\\n",
      "0      I was wondering if anyone out there could enli...       7   \n",
      "1      A fair number of brave souls who upgraded thei...       4   \n",
      "2      well folks, my mac plus finally gave up the gh...       4   \n",
      "3      \\nDo you have Weitek's address/phone number?  ...       1   \n",
      "4      From article <C5owCB.n3p@world.std.com>, by to...      14   \n",
      "...                                                  ...     ...   \n",
      "11309  DN> From: nyeda@cnsvax.uwec.edu (David Nye)\\nD...      13   \n",
      "11310  I have a (very old) Mac 512k and a Mac Plus, b...       4   \n",
      "11311  I just installed a DX2-66 CPU in a clone mothe...       3   \n",
      "11312  \\nWouldn't this require a hyper-sphere.  In 3-...       1   \n",
      "11313  Stolen from Pasadena between 4:30 and 6:30 pm ...       8   \n",
      "\n",
      "                       category  \n",
      "0                     rec.autos  \n",
      "1         comp.sys.mac.hardware  \n",
      "2         comp.sys.mac.hardware  \n",
      "3                 comp.graphics  \n",
      "4                     sci.space  \n",
      "...                         ...  \n",
      "11309                   sci.med  \n",
      "11310     comp.sys.mac.hardware  \n",
      "11311  comp.sys.ibm.pc.hardware  \n",
      "11312             comp.graphics  \n",
      "11313           rec.motorcycles  \n",
      "\n",
      "[11314 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "df=pd.read_csv(\"Downloads/nlp_train.csv\")\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a1fe0db4-5a24-4168-b43a-c08ae1347856",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "005c3d99-b893-4649-aa96-55b2d01aac47",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "# Load the full 20 Newsgroups dataset\n",
    "newsgroups_data = fetch_20newsgroups(subset='all')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "293001f4-b17f-42e4-8360-b6bbd973e0f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "# Load only the training subset\n",
    "newsgroups_train = fetch_20newsgroups(subset='train')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f1b13a-8604-417d-8215-ac69addfe3f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "# Load only the training subset\n",
    "newsgroups_train = fetch_20newsgroups(subset='test')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "427c42bb-9c37-46b8-8682-9285d35d2bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the first 5 documents and their corresponding target category\n",
    "for i in range(5):\n",
    "    print(f\"\\nDocument {i+1}:\\n{'-'*40}\")\n",
    "    print(newsgroups_train.data[i][:500])  # Print first 500 characters for brevity\n",
    "    print(f\"\\nCategory: {newsgroups_train.target_names[newsgroups_train.target[i]]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8482d85d-98d2-45ec-8ca1-e457d87b8265",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Create a TF-IDF vectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Fit and transform the training data\n",
    "X_train_tfidf = vectorizer.fit_transform(newsgroups_train.data)\n",
    "\n",
    "# Optionally, transform the test data too if you're doing classification later\n",
    "X_test_tfidf = vectorizer.transform(newsgroups_test.data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f147ff0-5d19-4e63-b8ea-e37ddc754be8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
